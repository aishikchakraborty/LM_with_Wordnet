Namespace(adaptive=False, annotated_dir=None, batch_size=2000, bptt=35, clip=0.25, cuda=True, data='wikitext-2', distance='cosine', dropout=0.2, emsize=300, epochs=14, extend_wn=False, fixed_wn=False, gpu=0, lex_rels=[], log_interval=200, lower=True, lr=20.0, margin=1, model='skipgram', nce=False, nce_loss='nce', nhid=300, nlayers=2, numpy_seed=1337, onnx_export='', optim='sgd', patience=1, random_seed=13370, random_wn=False, reg=False, rnn_type='LSTM', save='output/wikitext-2_skipgram_vanilla_lower/2019_03_11_12_28', save_emb='output/wikitext-2_skipgram_vanilla_lower/2019_03_11_12_28', tied=False, torch_seed=133, wn_hid=100, wn_ratio=0.1)
[10, 25, 35, 45]
Lex Rel List: []
Vocab Saved
| epoch   1 |   200/ 1026 batches | lr 20.0000000000 | ms/batch 136.94 | loss 10.76 | ppl 22026.47 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   1 |   400/ 1026 batches | lr 20.0000000000 | ms/batch 135.96 | loss  3.51 | ppl    33.51 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   1 |   600/ 1026 batches | lr 20.0000000000 | ms/batch 135.74 | loss  1.32 | ppl     3.76 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   1 |   800/ 1026 batches | lr 20.0000000000 | ms/batch 135.84 | loss  0.82 | ppl     2.27 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   1 |  1000/ 1026 batches | lr 20.0000000000 | ms/batch 135.90 | loss  0.59 | ppl     1.81 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00

-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 151.59s | valid loss  0.41 | valid ppl     1.51 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00
-----------------------------------------------------------------------------------------
Saving learnt embeddings : output/wikitext-2_skipgram_vanilla_lower/2019_03_11_12_28/emb_wikitext-2_skipgram_vanilla_300_300_100_cosine.pkl
| epoch   2 |   200/ 1026 batches | lr 20.0000000000 | ms/batch 136.43 | loss  0.44 | ppl     1.55 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   2 |   400/ 1026 batches | lr 20.0000000000 | ms/batch 136.06 | loss  0.34 | ppl     1.41 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   2 |   600/ 1026 batches | lr 20.0000000000 | ms/batch 136.20 | loss  0.29 | ppl     1.33 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   2 |   800/ 1026 batches | lr 20.0000000000 | ms/batch 135.72 | loss  0.25 | ppl     1.28 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   2 |  1000/ 1026 batches | lr 20.0000000000 | ms/batch 135.96 | loss  0.22 | ppl     1.24 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00

-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 151.58s | valid loss  0.16 | valid ppl     1.18 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00
-----------------------------------------------------------------------------------------
Saving learnt embeddings : output/wikitext-2_skipgram_vanilla_lower/2019_03_11_12_28/emb_wikitext-2_skipgram_vanilla_300_300_100_cosine.pkl
| epoch   3 |   200/ 1026 batches | lr 20.0000000000 | ms/batch 136.77 | loss  0.19 | ppl     1.20 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   3 |   400/ 1026 batches | lr 20.0000000000 | ms/batch 136.19 | loss  0.16 | ppl     1.17 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   3 |   600/ 1026 batches | lr 20.0000000000 | ms/batch 135.84 | loss  0.14 | ppl     1.15 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   3 |   800/ 1026 batches | lr 20.0000000000 | ms/batch 136.15 | loss  0.13 | ppl     1.14 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   3 |  1000/ 1026 batches | lr 20.0000000000 | ms/batch 135.75 | loss  0.12 | ppl     1.13 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00

-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 151.66s | valid loss  0.10 | valid ppl     1.10 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00
-----------------------------------------------------------------------------------------
Saving learnt embeddings : output/wikitext-2_skipgram_vanilla_lower/2019_03_11_12_28/emb_wikitext-2_skipgram_vanilla_300_300_100_cosine.pkl
| epoch   4 |   200/ 1026 batches | lr 20.0000000000 | ms/batch 136.78 | loss  0.11 | ppl     1.12 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   4 |   400/ 1026 batches | lr 20.0000000000 | ms/batch 135.83 | loss  0.10 | ppl     1.10 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   4 |   600/ 1026 batches | lr 20.0000000000 | ms/batch 136.36 | loss  0.09 | ppl     1.10 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   4 |   800/ 1026 batches | lr 20.0000000000 | ms/batch 135.89 | loss  0.09 | ppl     1.09 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00
| epoch   4 |  1000/ 1026 batches | lr 20.0000000000 | ms/batch 135.94 | loss  0.08 | ppl     1.08 | syn loss  0.00 | ant loss  0.00 | hyp loss  0.00 | mer loss  0.00 | reg_loss  0.00

